{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede9befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import START, END, StateGraph  \n",
    "from langgraph.graph.message import add_messages   #reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75e7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages] # updates the messhaes rather than overwriding them.\n",
    "    \n",
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9fe19bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27bd0efb110>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a0ddde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8977709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = ChatGroq(model='llama-3.3-70b-versatile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7944358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000027BD388BB30>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000027BD3888F50>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89a54859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state:State):\n",
    "    return {\"messages\":[llm.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fe8d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"llmchatbot\", chatbot)\n",
    "graph.add_edge(START, \"llmchatbot\")\n",
    "graph.add_edge(\"llmchatbot\",END)\n",
    "\n",
    "graph=graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccae98bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=graph.invoke({\"messages\":[\"hi\"]})\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26df9302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or topics you'd like to discuss. How about you? How's your day going?\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\":\"Hi how are you\"}):\n",
    "    for value in event.values():\n",
    "        print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d8ecd",
   "metadata": {},
   "source": [
    "LLM with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5bbf7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699cf6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
